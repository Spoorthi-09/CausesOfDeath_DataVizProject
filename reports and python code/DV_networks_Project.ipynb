{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGf28A-a4BJY"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Read the data into a Pandas DataFrame from the CSV file\n",
        "data = pd.read_csv(\"deaths_gdp_obesity_sorted.csv\")\n",
        "\n",
        "# Filter the data for the year 2019\n",
        "data_2019 = data[data['Year'] == 2019]\n",
        "\n",
        "# Create a graph using networkx\n",
        "G = nx.Graph()\n",
        "\n",
        "# Define a function to determine the range for max deaths\n",
        "def get_death_range(deaths):\n",
        "    return (deaths // 5000) * 5000\n",
        "\n",
        "# Iterate over each row in the DataFrame to add nodes\n",
        "for index, row in data_2019.iterrows():\n",
        "    country_name = row['Country/Territory']\n",
        "    country_code = row['Code']\n",
        "\n",
        "    # Exclude specific columns from consideration\n",
        "    excluded_columns = ['Country/Territory', 'Code', 'Year', 'total_deaths', 'Value', 'Obesity (%)']\n",
        "    relevant_columns = [col for col in row.index if col not in excluded_columns]\n",
        "\n",
        "    # Find the column with the maximum value\n",
        "    max_death_disease = max(relevant_columns, key=lambda col: (row[col], col) if pd.notna(row[col]) else (0, col))\n",
        "    max_death_value = row[max_death_disease]\n",
        "\n",
        "    # Extract the actual value from the tuple (value, column_name)\n",
        "    max_death_disease = max_death_disease\n",
        "\n",
        "    # Add nodes\n",
        "    G.add_node(country_code, name=country_name, disease=max_death_disease, deaths=max_death_value)\n",
        "\n",
        "# Iterate over each pair of nodes to add links based on disease matching and death range\n",
        "for source_node in G.nodes():\n",
        "    for target_node in G.nodes():\n",
        "        if source_node != target_node:\n",
        "            source_data = G.nodes[source_node]\n",
        "            target_data = G.nodes[target_node]\n",
        "\n",
        "            # Determine the death range for source and target\n",
        "            source_range = get_death_range(source_data['deaths'])\n",
        "            target_range = get_death_range(target_data['deaths'])\n",
        "\n",
        "            # Add link only if the diseases match, death ranges match, and the source is not already linked to the target\n",
        "            if source_data['disease'] == target_data['disease'] and source_range == target_range \\\n",
        "                    and not G.has_edge(source_node, target_node) and not G.has_edge(target_node, source_node):\n",
        "                G.add_edge(source_node, target_node, disease=source_data['disease'], death_range=source_range)\n",
        "\n",
        "# Create a dictionary in the desired format for JSON\n",
        "network_data = {\n",
        "    \"nodes\": [{\"id\": node, \"name\": G.nodes[node]['name'], \"disease\": G.nodes[node]['disease'], \"deaths\": G.nodes[node]['deaths']} for node in G.nodes()],\n",
        "    \"links\": [{\"source\": source, \"target\": target, \"disease\": G[source][target]['disease'], \"death_range\": G[source][target]['death_range']} for source, target in G.edges()]\n",
        "}\n",
        "\n",
        "# Convert the dictionary to JSON\n",
        "json_data = json.dumps(network_data, indent=2)\n",
        "\n",
        "# Save the JSON data to a file\n",
        "with open(\"network_data.json\", \"w\") as json_file:\n",
        "    json_file.write(json_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Read the data into a Pandas DataFrame from the CSV file\n",
        "data = pd.read_csv(\"deaths_gdp_obesity_sorted.csv\")\n",
        "\n",
        "# Create a graph using networkx\n",
        "G = nx.Graph()\n",
        "\n",
        "# Define a function to determine the range for max deaths\n",
        "def get_death_range(deaths):\n",
        "    return (deaths // 5000) * 5000\n",
        "\n",
        "# Create a dictionary to store data for each year\n",
        "all_years_data = {}\n",
        "\n",
        "# Iterate over each year in the data\n",
        "for year in range(1990, 2020):  # Assuming the data spans from 1990 to 2019\n",
        "    # Filter the data for the current year\n",
        "    data_year = data[data['Year'] == year]\n",
        "\n",
        "    # Iterate over each row in the DataFrame to add nodes\n",
        "    for index, row in data_year.iterrows():\n",
        "        country_name = row['Country/Territory']\n",
        "        country_code = row['Code']\n",
        "\n",
        "        # Exclude specific columns from consideration\n",
        "        excluded_columns = ['Country/Territory', 'Code', 'Year', 'total_deaths', 'Value', 'Obesity (%)']\n",
        "        relevant_columns = [col for col in row.index if col not in excluded_columns]\n",
        "\n",
        "        # Find the column with the maximum value\n",
        "        max_death_disease = max(relevant_columns, key=lambda col: (row[col], col) if pd.notna(row[col]) else (0, col))\n",
        "        max_death_value = row[max_death_disease]\n",
        "\n",
        "        # Extract the actual value from the tuple (value, column_name)\n",
        "        max_death_disease = max_death_disease\n",
        "\n",
        "        # Add nodes\n",
        "        G.add_node(country_code, name=country_name, disease=max_death_disease, deaths=max_death_value, year=year)\n",
        "\n",
        "    # Iterate over each pair of nodes to add links based on disease matching and death range\n",
        "    for source_node in G.nodes():\n",
        "        for target_node in G.nodes():\n",
        "            if source_node != target_node:\n",
        "                source_data = G.nodes[source_node]\n",
        "                target_data = G.nodes[target_node]\n",
        "\n",
        "                # Determine the death range for source and target\n",
        "                source_range = get_death_range(source_data['deaths'])\n",
        "                target_range = get_death_range(target_data['deaths'])\n",
        "\n",
        "                # Add link only if the diseases match, death ranges match, and the source is not already linked to the target\n",
        "                if source_data['disease'] == target_data['disease'] and source_range == target_range \\\n",
        "                        and not G.has_edge(source_node, target_node) and not G.has_edge(target_node, source_node):\n",
        "                    G.add_edge(source_node, target_node, disease=source_data['disease'], death_range=source_range)\n",
        "\n",
        "    # Create a dictionary for the current year\n",
        "    year_data = {\n",
        "        \"nodes\": [{\"id\": node, \"name\": G.nodes[node]['name'], \"disease\": G.nodes[node]['disease'], \"deaths\": G.nodes[node]['deaths'], \"year\": G.nodes[node]['year']} for node in G.nodes()],\n",
        "        \"links\": [{\"source\": source, \"target\": target, \"disease\": G[source][target]['disease'], \"death_range\": G[source][target]['death_range']} for source, target in G.edges()]\n",
        "    }\n",
        "\n",
        "    # Store the data for the current year in the dictionary\n",
        "    all_years_data[year] = year_data\n",
        "\n",
        "    # Clear the graph for the next iteration\n",
        "    G.clear()\n",
        "\n",
        "# Convert the dictionary to JSON\n",
        "json_data = json.dumps({\"years\": all_years_data}, indent=2)\n",
        "\n",
        "# Save the JSON data to a file\n",
        "with open(\"network_data_multi_layered.json\", \"w\") as json_file:\n",
        "    json_file.write(json_data)\n"
      ],
      "metadata": {
        "id": "3K5Boil8EY96"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}